 Welcome to Generative AI for Everyone. Since the release of ChatGBT, AI, specifically Generative AI, has caught the attention of many individuals, corporations, and governments. It is a very disruptive technology that is already changing how many people learn and work. Many developers think that Generative AI will empower many people and lead to productivity gains and also make a significant contribution to global economic growth. But there could be downsides as well, such as job loss or worse that some people worry about. In this course, you learn what Generative AI is, what it can and cannot do, and also how to use it in your own work or business. Because Generative AI is so new, there is still a lot of misinformation out there. And so in this course, I hope to convey an accurate, non-technical understanding of what it really is and also work with you to think through how you can best make use of this technology. This course does not assume any technical or AI background and is designed to be useful to anyone in business, science, engineering, the humanities, arts, or other sectors. So with that, let's dive in. What is Generative AI? This term refers to AI or artificial intelligence systems that can produce high-quality content, specifically text, images, and audio. One of the best-known Generative AI or Gen AI systems is OpenAI's ChatGPT, which can follow instructions to carry out tasks like write three captions for a social media post about a new line of sunglasses for robots and have it generate a variety of creative outputs. And many users are familiar with websites or direct-to-consumer applications that can generate text like this. Other examples include BOD, which is offered by Google, as well as BingChat, offered by Microsoft. But there are now many companies that are offering user interfaces that let you type in some text called a prompt and will generate a response. But beyond these consumer applications, there's one other application of Generative AI that I think may turn out to be even more impactful in the long term, which is the use of Generative AI as a developer tool. AI is already pervasive in our lives, and many of us use it dozens of times a day or more without even thinking about it. Every time you do a web search on Google or Bing, that's AI. Every time you use your credit card, there's probably an AI checking if it really is you using your credit card. Or every time you go to a website like Amazon or Netflix and it recommends products of movies to you, that's AI. But many AI systems have been complex and expensive to build. And Generative AI is making many AI applications much easier to build. And this means that the number and variety of AI product offerings is blossoming because it's becoming much cheaper to build certain AI applications compared to before. So in this course, one of the themes we'll touch on a few times as well will be how gens of AI may allow your business to much more inexpensively build very valuable AI applications. And you learn best practices for identifying and exploring whether or not such applications might be useful for a given business. I've described Genitive AI as generating text images and audio. And of these three types of contents, the biggest impact so far has been on text generation. But it can also generate images where given instructions, a different type of prompt, it can generate beautiful images like this one or even a photo realistic image like this. Genitive AI can also generate audio. For example, here is a voice clone of me. Hi, I'm an AI generated voice clone of Andrew. Andrew never actually said these words. Isn't that cool? And you can also put audio together with image or even video generation to create a video clone of me like this. Hi, I'm a video clone of Andrew. It's nice to meet you. The ability of systems like ChatGPT and BOT to generate text seems almost magical. And they do represent a big step forward for AI technology. But how does text generation actually work? In this video, we'll take a look at what actually underlies the Genitive AI technology. And this will hopefully help you understand what you can use it for and also when you might not want to count on it. Let's take a look. Let's start by looking at where Genitive AI fits within the AI landscape. There's a lot of buzz and excitement and also hype about AI. And I think a useful way to think of AI is as a collection or as a set of tools. One of the most important tools in AI is supervised learning, which turns out to be really good at labeling things. Don't worry if you don't know what this means. We'll talk more about it on the next slide. And a second tool that started to work really well only fairly recently is Genitive AI. If you study AI, you may recognize that there are other tools as well, such as things called unsupervised learning and reinforcement learning. But for the purposes of this course, I'm going to touch briefly on what is supervised learning and then spend most of our time talking about Genitive AI. And these two, supervised learning and Genitive AI, are the two most important tools in AI today. And for most business use cases, you should be fine if you just not worry about the other tools than these for now. Before describing how Genitive AI works, let me briefly describe what is supervised learning, because it turns out Genitive AI is built using supervised learning. Supervised learning is a technology that has made computers very good when given an input, which I'm going to call A, to generate a corresponding output, which I'm going to call B. To look at a few examples, given an email, supervised learning can decide if that email is spam or not. So the input A is an email and the output B is either 0 or 1, where 0 is not spam and 1 is spam. And this is how spam filters work today. As a second example, probably the most lucrative application, not the most inspiring, but lucrative for some companies that I've ever worked on was online advertising, where given an ad and some information about a user, an AI system can generate an output B corresponding to whether or not you're likely to click on that ad. And by showing slightly more relevant ads, this drives significant revenue for the online ad platforms. In self-driving cars and in driver assistance systems, supervised learning is used to take as input a picture of what's in front of your car and radar info and label that with the position of other cars. Given a medical x-ray, it can try to label that with a medical diagnosis. I've also done a lot of work in manufacturing defect inspection, where you can have a system take a picture of a phone as it rolls off the assembly line and check if the phone has any scratches or the defects. Or in speech recognition, the input a would be a piece of audio and we would label that with a text transcript. Or as a final example, if you run a restaurant or some other business where occasionally you have reviews written about your business or your products, supervised learning can read those reviews and label each one as having either a positive or a negative sentiment. And this is useful for reputation monitoring of the business. So it turns out the decade of around 2010 to 2020 was a decade of large scale supervised learning. And I want to touch on this briefly because it turns out this laid the foundation for modern generative AI. But what we found starting around 2010 was that for a lot of applications, we had a lot of data. But even as we fed it more data, its performance wasn't getting that much better if we were training small AI models. This means, for example, if you are building a speech recognition system, even as your AI listened to tens of thousands or hundreds of thousands of hours of data, that's a lot of data. It didn't get that much more accurate compared to a system that listened to only a smaller amount of audio data. But what more and more researchers started to realize through this period is if you were to train a very large AI model, meaning an AI model on very fast, very powerful computers with a lot of memory, then its performance as you fed it more and more data would just keep on getting better and better. In fact, years ago when I started and led the Google Brain Team, the primary mission that I set by the Google Brain Team in the early days was I said let's just build really, really large AI models and feed them a lot of data. And fortunately that recipe worked and ended up driving a lot of AI progress at Google. Large scale supervised learning remains important today. But this idea of very large models for labeling things is how we got to generative AI today. Let's look at how generative AI generates text using a technology called Large Language Models. Here's one way that Large Language Models, which are abbreviated LLM, can generate text. Given an input like, I love eating, this is called a prompt. An LLM can then complete the sentence with maybe bagels or cream cheese. Or if you run it a second time, it might say, my mother's meatlo. Or if you run it a third time, maybe it'll say, I was with friends. So how does an LLM, a large language model, generate this output? It turns out that LLMs are built by using supervised learning. That's that technology to input A and output a label B. It uses supervised learning to repeatedly predict what is the next word. For example, if an AI system has read on the internet a sentence like, My favorite food is a bagel with cream cheese. Then this one sentence will be turned into a lot of data points for it to try to learn to predict the next word. Especially given this sentence, we now have one data point that says, Given the phrase, my favorite food is a, what do you think is the next word? In this case, the right answer is bagel. And also given my favorite food is a bagel. What do you think is the next word? It's with, and so on. So this one sentence is turned into multiple inputs A and outputs B for it to try to learn from. Where the LLM is learning given a few words to predict what is the next word that comes out there. When you train a very large AI system on a lot of data. A lot of data for LLMs means hundreds of billions of words. And in some cases, more than a trillion words. Then you get a large language model like ChatGPT. That's given a prompt is very good at generating some additional words in response to that prompt. But now I'm omitting some technical details. Specifically, next week, we'll talk about a process that makes LLMs not just predict the next word, but actually learn to follow instructions and also be safe in what it outputs. But at the heart of LLMs is this technology that's learned from a lot of data to predict what is the next word. So that's how large language models work. They're trained to repeatedly predict the next word. And it turns out that many people, perhaps including you, are already finding these models useful for day-to-day activities at work, to help with writing, to find basic information, or to be a thought partner to help think things through. What is generative AI good for? One of the reasons that question is a bit hard to answer is because AI is a general-purpose technology. Unlike a lot of technologies, like a car, which is good for transportation, or a microwave oven, good for heating up food, AI isn't useful just for one thing. It's useful for a lot of things. And that almost makes it harder to talk about. But let's take a look at what a general-purpose technology really means. Similar to electricity, AI is useful for many tasks. If we ask you, what is electricity good for? Or what is the internet good for? These are other general-purpose technologies, and it's almost difficult to think, what is electricity good for? Because it's so pervasive, and it's used around us for so many different things. In fact, as you saw earlier, supervised learning is useful for many tasks, like spam filtering, advertising, speech recognition, and many others. And generative AI is like this too. In the last video, you saw a few of the tasks that an LLM can carry out, answering certain questions and helping with writing, for example.